
<p align="center">
  <img src="https://github.com/mallouliemna09-lang/Recherche-de-critiques-similaires/blob/main/Interface.png" alt="AperÃ§u de l'application Streamlit" width="90%">
</p>

# ğŸ¬ SystÃ¨me de recommandation de critiques similaires

Une interface Streamlit interactive permettant de retrouver les critiques les plus similaires dâ€™un mÃªme film, Ã  partir dâ€™un texte saisi par lâ€™utilisateur.

---

## ğŸ§­ Architecture du systÃ¨me

Ce diagramme illustre le flux complet du systÃ¨me : depuis le chargement des critiques jusquâ€™Ã  la recherche de similaritÃ© dans Streamlit.

```mermaid
flowchart LR

    %% --- Sources de donnÃ©es ---
    subgraph DATA["ğŸ“‚ DonnÃ©es d'entrÃ©e"]
        A1[interstellar_critiques.csv]
        A2[fightclub_critiques.csv]
    end

    %% --- Pipeline offline ---
    subgraph PIPELINE["ğŸ›  PrÃ©traitement & Indexation"]
        B1[Nettoyage HTML strip_html()]
        B2[ConcatÃ©nation titre + contenu â†’ full_review]
        B3[Chunking 512 tokens + overlap]
        B4[Embedding des chunks MiniLM multilingue]
        B5[Construction index FAISS (IndexFlatIP)]
        B6[Sauvegarde des mÃ©tadonnÃ©es meta_chunks_<film>.csv]
    end

    %% --- Artifacts par film ---
    subgraph ARTIFACTS["ğŸ’¾ Artifacts par film"]
        C1[faiss_Interstellar.index]
        C2[meta_chunks_Interstellar.csv]
        C3[faiss_FightClub.index]
        C4[meta_chunks_FightClub.csv]
    end

    %% --- Interface interactive ---
    subgraph APP["ğŸŒ Application Streamlit"]
        D1[Choix du film selectbox("Interstellar"/"Fight Club")]
        D2[Saisie / Coller une critique]
        D3[Encodage de la requÃªte MiniLM]
        D4[Recherche dans FAISSdu film choisi]
        D5[Regroupement par critique originale + tri par score]
        D6[Affichage des critiques similaires + score de similaritÃ©]
    end

    %% Flux de gauche Ã  droite
    A1 --> B1
    A2 --> B1
    B1 --> B2 --> B3 --> B4 --> B5 --> ARTIFACTS
    B4 --> B6 --> ARTIFACTS

    %% SÃ©lection dynamique Ã  l'exÃ©cution
    ARTIFACTS -->|load_resources_for_movie(movie_name)| D1
    D1 --> D2 --> D3 --> D4 --> D5 --> D6

## ğŸ’¡DÃ©marche de conception

Jâ€™ai adoptÃ© une approche exploratoire et progressive pour concevoir un moteur de recherche sÃ©mantique robuste :

1. **Analyse du besoin produit :**  
   Je me suis dâ€™abord concentrÃ©e sur la finalitÃ© fonctionnelle : proposer des critiques similaires dâ€™un mÃªme film, non pas sur des mots-clÃ©s identiques, mais sur le sens global.

2. **Exploration des donnÃ©es :**  
   En examinant le CSV, jâ€™ai constatÃ© que les critiques Ã©taient souvent longues, riches en HTML et comportaient Ã  la fois un titre et un contenu textuel dÃ©taillÃ©.
   Jâ€™ai donc dÃ©cidÃ© de fusionner les deux colonnes et de supprimer les balises HTML via BeautifulSoup pour obtenir un texte propre (full_review).

3. **PremiÃ¨re approche :**  
   Jâ€™ai commencÃ© par encoder directement chaque critique avec le modÃ¨le
   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (dÃ©jÃ  utilisÃ© lors de mon prÃ©cÃ©dent stage pour un moteur de recherche sÃ©mantique basÃ© sur FAISS).
   Cette approche a confirmÃ© la validitÃ© du modÃ¨le, mais jâ€™ai rapidement identifiÃ© une limite.

4. **ProblÃ¨me rencontrÃ© :**  
   Certaines critiques dÃ©passent la limite de **512 tokens**, entraÃ®nant une perte dâ€™information.

5. **AmÃ©lioration :**  
   Jâ€™ai alors introduit une segmentation du texte (chunking) avec chevauchement (stride=400) afin de prÃ©server la cohÃ©rence sÃ©mantique dâ€™un texte long et Ã©viter de couper une idÃ©e en deux. Un fichier `meta_chunks.csv` relie chaque chunk Ã  sa critique dâ€™origine.  

6. **Recherche amÃ©liorÃ©e :**  
   - Si la requÃªte est longue, elle est Ã©galement dÃ©coupÃ©e en chunks  
   - Les rÃ©sultats sont ensuite **agrÃ©gÃ©s et dÃ©dupliquÃ©s par critique originale**

7. **RÃ©sultats observÃ©s :**  
   - Copie exacte dâ€™une critique â†’ score â‰ˆ **1.0**  
   - Reformulation / rÃ©sumÃ© â†’ score â‰ˆ **0.75 â€“ 0.85**

8. **Adaptation multi-films:**

   Lâ€™Ã©noncÃ© imposant que les recommandations concernent uniquement le mÃªme film, jâ€™ai adaptÃ© la logique dâ€™indexation :
   Jâ€™ai remplacÃ© la fonction build_vector_database() par une version gÃ©nÃ©rique paramÃ©trÃ©e (build_vector_database_for_movie) capable de gÃ©nÃ©rer un index FAISS pour chaque film sÃ©parÃ©ment Ã  partir de son CSV (interstellar_critiques.csv et fightclub_critiques.csv).

   Chaque film dispose ainsi de ses propres fichiers :
      -faiss_interstellar.index, meta_chunks_interstellar.csv
      -faiss_fightclub.index, meta_chunks_fightclub.csv

   Cette sÃ©paration garantit que les critiques suggÃ©rÃ©es appartiennent toujours au mÃªme film que la requÃªte.

   Dans lâ€™application Streamlit, jâ€™ai ajoutÃ© un sÃ©lecteur (movie_choice) permettant de choisir le film avant la recherche.
   Selon ce choix, le moteur charge automatiquement lâ€™index FAISS correspondant.
---

## âš™ï¸ Choix techniques justifiÃ©s

| Composant | Choix | Justification |
|------------|--------|----------------|
| **ModÃ¨le dâ€™embedding** | `paraphrase-multilingual-MiniLM-L12-v2` | LÃ©ger, performant, multilingue (franÃ§ais inclus). DÃ©jÃ  utilisÃ© dans un projet prÃ©cÃ©dent. |
| **Moteur de recherche** | **FAISS (IndexFlatIP)** | Recherche vectorielle rapide sur CPU et open-source Produit scalaire â‰ˆ similaritÃ© cosinus. |
| **Normalisation** | `normalize_embeddings=True` | Permet de comparer les vecteurs sur une mÃªme Ã©chelle. |
| **Interface utilisateur** | `Streamlit` | Permet de crÃ©er rapidement une interface web interactive. DÃ©jÃ  utilisÃ© dans mon dernier stage. |

---

## ğŸ““ Notebook dâ€™exploration

Jâ€™ai inclus un **notebook Jupyter (`exploration.ipynb`)** retraÃ§ant toutes les Ã©tapes de conception :

1. **Inspection et nettoyage :**  
    -Fusion review_title + review_content
    -Suppression des balises HTML via BeautifulSoup
    -CrÃ©ation dâ€™une colonne full_review pour les textes lisibles
2. **Analyse de la longueur :**  
   -Comptage des tokens avec le tokenizer HuggingFace
   -Constat : plusieurs critiques dÃ©passent 512 tokens

3. **PremiÃ¨re approche :**  
   -Encodage direct avec MiniLM-L12-v2
   -Indexation FAISS simple 

4. **ProblÃ¨me identifiÃ© :**  
   Troncature des textes longs â†’ perte de sens.  

5. **AmÃ©lioration :**  
   -Introduction du chunking avec overlap
   -Indexation de chaque chunk dans FAISS
   -Sauvegarde des mÃ©tadonnÃ©es (meta_chunks.csv)

6. **Recherche finale :**  
   -Version simple : requÃªte encodÃ©e en un seul vecteur
   -Version amÃ©liorÃ©e : requÃªte segmentÃ©e en chunks et agrÃ©gation des rÃ©sultats

7. **RÃ©sultats :**  
   - Texte identique â†’ score 1.0  
   - Reformulation â†’ critiques similaires retrouvÃ©es (score â‰ˆ 0.8)  


ğŸš€ ExÃ©cution
1ï¸âƒ£ Installer les dÃ©pendances
```powershell
     pip install -r requirements.txt
```
2ï¸âƒ£ Lancer lâ€™application Streamlit
```powershell
     streamlit run app.py
```

