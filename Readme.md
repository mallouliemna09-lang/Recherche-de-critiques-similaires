# ğŸ¬ SystÃ¨me de recommandation de critiques similaires 

## ğŸ’¡DÃ©marche de conception

Jâ€™ai adoptÃ© une approche exploratoire et progressive pour concevoir un moteur de recherche sÃ©mantique robuste :

1. **Analyse du besoin produit :**  
   Je me suis dâ€™abord concentrÃ©e sur la finalitÃ© fonctionnelle : proposer des critiques similaires dâ€™un mÃªme film, non pas sur des mots-clÃ©s identiques, mais sur le sens global.

2. **Exploration des donnÃ©es :**  
   En examinant le CSV, jâ€™ai constatÃ© que les critiques Ã©taient souvent longues, riches en HTML et comportaient Ã  la fois un titre et un contenu textuel dÃ©taillÃ©.
   Jâ€™ai donc dÃ©cidÃ© de fusionner les deux colonnes et de supprimer les balises HTML via BeautifulSoup pour obtenir un texte propre (full_review).

3. **PremiÃ¨re approche :**  
   Jâ€™ai commencÃ© par encoder directement chaque critique avec le modÃ¨le
   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (dÃ©jÃ  utilisÃ© lors de mon prÃ©cÃ©dent stage pour un moteur de recherche sÃ©mantique basÃ© sur FAISS).
   Cette approche a confirmÃ© la validitÃ© du modÃ¨le, mais jâ€™ai rapidement identifiÃ© une limite.

4. **ProblÃ¨me rencontrÃ© :**  
   Certaines critiques dÃ©passent la limite de **512 tokens**, entraÃ®nant une perte dâ€™information.

5. **AmÃ©lioration :**  
   Jâ€™ai alors introduit une segmentation du texte (chunking) avec chevauchement (stride=400) afin de prÃ©server la cohÃ©rence sÃ©mantique dâ€™un texte long et Ã©viter de couper une idÃ©e en deux. Un fichier `meta_chunks.csv` relie chaque chunk Ã  sa critique dâ€™origine.  

6. **Recherche amÃ©liorÃ©e :**  
   - Si la requÃªte est longue, elle est Ã©galement dÃ©coupÃ©e en chunks  
   - Les rÃ©sultats sont ensuite **agrÃ©gÃ©s et dÃ©dupliquÃ©s par critique originale**

7. **RÃ©sultats observÃ©s :**  
   - Copie exacte dâ€™une critique â†’ score â‰ˆ **1.0**  
   - Reformulation / rÃ©sumÃ© â†’ score â‰ˆ **0.75 â€“ 0.85**
---

## âš™ï¸ Choix techniques justifiÃ©s

| Composant | Choix | Justification |
|------------|--------|----------------|
| **ModÃ¨le dâ€™embedding** | `paraphrase-multilingual-MiniLM-L12-v2` | LÃ©ger, performant, multilingue (franÃ§ais inclus). DÃ©jÃ  utilisÃ© dans un projet prÃ©cÃ©dent. |
| **Moteur de recherche** | **FAISS (IndexFlatIP)** | Recherche vectorielle rapide sur CPU et open-source Produit scalaire â‰ˆ similaritÃ© cosinus. |
| **Normalisation** | `normalize_embeddings=True` | Permet de comparer les vecteurs sur une mÃªme Ã©chelle. |
| **Interface utilisateur** | `Streamlit` | Permet de crÃ©er rapidement une interface web interactive. DÃ©jÃ  utilisÃ© dans mon dernier stage. |

---

## ğŸ““ Notebook dâ€™exploration

Jâ€™ai inclus un **notebook Jupyter (`exploration.ipynb`)** retraÃ§ant toutes les Ã©tapes de conception :

1. **Inspection et nettoyage :**  
    -Fusion review_title + review_content
    -Suppression des balises HTML via BeautifulSoup
    -CrÃ©ation dâ€™une colonne full_review pour les textes lisibles
2. **Analyse de la longueur :**  
   -Comptage des tokens avec le tokenizer HuggingFace
   -Constat : plusieurs critiques dÃ©passent 512 tokens

3. **PremiÃ¨re approche :**  
   -Encodage direct avec MiniLM-L12-v2
   -Indexation FAISS simple 

4. **ProblÃ¨me identifiÃ© :**  
   Troncature des textes longs â†’ perte de sens.  

5. **AmÃ©lioration :**  
   -Introduction du chunking avec overlap
   -Indexation de chaque chunk dans FAISS
   -Sauvegarde des mÃ©tadonnÃ©es (meta_chunks.csv)

6. **Recherche finale :**  
   -Version simple : requÃªte encodÃ©e en un seul vecteur
   -Version amÃ©liorÃ©e : requÃªte segmentÃ©e en chunks et agrÃ©gation des rÃ©sultats

7. **RÃ©sultats :**  
   - Texte identique â†’ score 1.0  
   - Reformulation â†’ critiques similaires retrouvÃ©es (score â‰ˆ 0.8)  


ğŸš€ ExÃ©cution
1ï¸âƒ£ Installer les dÃ©pendances
```powershell
     pip install -r requirements.txt
```
2ï¸âƒ£ Lancer lâ€™application Streamlit
```powershell
     streamlit run app.py
```

